{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import sys\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('../..')\n",
    "from helpers.metrics import brier_multi, CalibrationErrors, classification_error\n",
    "from helpers.settings import models_folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "def load_mnist():\n",
    "    num_classes = 10\n",
    "    img_rows, img_cols = 28, 28\n",
    "\n",
    "    (x_train_val, y_train_val), (x_test, y_test) = mnist.load_data()\n",
    "    x_train_val = x_train_val.reshape(x_train_val.shape[0], img_rows, img_cols, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "\n",
    "\n",
    "\n",
    "    x_train_val = x_train_val.astype('float32')\n",
    "    x_test = x_test.astype('float32')\n",
    "\n",
    "    x_train_val /= 255\n",
    "    x_test /= 255\n",
    "\n",
    "    y_train_val = to_categorical(y_train_val, num_classes)\n",
    "    y_test = to_categorical(y_test, num_classes)\n",
    "\n",
    "    x_train = x_train_val[:50000]\n",
    "    y_train = y_train_val[:50000]\n",
    "    x_val = x_train_val[50000:]\n",
    "    y_val = y_train_val[50000:]\n",
    "    return (x_train, y_train), (x_val, y_val), (x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_val, y_val), (x_test, y_test) = load_mnist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "* The model is similar to the one that was used in Deep Ensembles and XXX paper\n",
    "* TODO: try a version of the model without batch normalization and study the effect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, BatchNormalization\n",
    "from keras.layers.core import Lambda\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten\n",
    "\n",
    "from keras.callbacks import CSVLogger, ModelCheckpoint\n",
    "from keras.optimizers import Adam\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn(num_classes=10):\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "    model.add(BatchNormalization(momentum=.9))\n",
    "    \n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(BatchNormalization(momentum=.9))\n",
    "    \n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Flatten())\n",
    "    \n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(BatchNormalization(momentum=.9))\n",
    "    \n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(BatchNormalization(momentum=.9))\n",
    "    \n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_models = 25\n",
    "epochs = 15\n",
    "learning_rate = 2.5e-4\n",
    "output_folder = os.path.join(models_folder, 'mnist_cnn')\n",
    "if not os.path.isdir(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "#\n",
    "output_baseline_folder = os.path.join(output_folder, 'baselines')\n",
    "if not os.path.isdir(output_baseline_folder):\n",
    "    os.makedirs(output_baseline_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skip training...\n",
      "skip training...\n",
      "skip training...\n",
      "skip training...\n",
      "skip training...\n",
      "skip training...\n",
      "skip training...\n",
      "skip training...\n",
      "skip training...\n",
      "skip training...\n",
      "skip training...\n",
      "skip training...\n",
      "skip training...\n",
      "skip training...\n",
      "skip training...\n",
      "skip training...\n",
      "skip training...\n",
      "skip training...\n",
      "skip training...\n",
      "skip training...\n",
      "skip training...\n",
      "skip training...\n",
      "skip training...\n",
      "skip training...\n",
      "skip training...\n"
     ]
    }
   ],
   "source": [
    "for i in range(n_models):\n",
    "    seed = i+17\n",
    "    # change the random state\n",
    "    np.random.seed(seed)\n",
    "    # creating output folder for each of the baseline models\n",
    "    output_model_folder = os.path.join(output_baseline_folder, str(seed))\n",
    "    if not os.path.isdir(output_model_folder):\n",
    "        os.mkdir(output_model_folder)\n",
    "    else:\n",
    "        print('skip training...')\n",
    "        continue\n",
    "    # callbacks for training\n",
    "    callbacks = list()\n",
    "    log = CSVLogger(os.path.join(output_model_folder, 'log.csv'))\n",
    "    callbacks.append(log)\n",
    "    checkpoint_path = os.path.join(output_model_folder, 'weights.{epoch:02d}.hdf5')\n",
    "    checkpoint = ModelCheckpoint(checkpoint_path, period=1, save_best_only=False, verbose=True)\n",
    "    callbacks.append(checkpoint)\n",
    "    # initialize and compile the model\n",
    "    model = cnn()\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=learning_rate), metrics=['accuracy'])\n",
    "    # train\n",
    "    model.fit(x_train, y_train, batch_size=128, epochs=epochs, verbose=1, callbacks=callbacks, validation_data=(x_val, y_val), shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(17, 17+n_models):\n",
    "    log = pd.read_csv(os.path.join(output_baseline_folder, str(i), 'log.csv'))\n",
    "    plt.figure(figsize=(8,2),dpi=100)\n",
    "    plt.subplots_adjust(wspace=0.5)\n",
    "    ax1 = plt.subplot(121)\n",
    "    ax2 = plt.subplot(122)\n",
    "    for metric_type in ['', 'val_']:\n",
    "        for key in log.keys():\n",
    "            if 'loss' in key and 'val' not in key:\n",
    "                p = ax1.plot(log[metric_type+ key], label=metric_type + key+str(i), linewidth=1)\n",
    "                c = p[-1].get_color()\n",
    "                ax1.plot(np.argmin(log[metric_type+key]), np.amin(log[metric_type+key]), \n",
    "                         '*', markersize=10, alpha=0.5, color = c)\n",
    "                ax1.set_title('min val NLL: {0:.3f}'.format(np.amin(log['val_' + key])))\n",
    "                ax1.set_ylabel('NLL')\n",
    "                ax1.set_xlabel('epochs')\n",
    "            if 'acc' in key and 'val' not in key:\n",
    "                p = ax2.plot(log[metric_type + key], label=metric_type + key+str(i), linewidth=1)\n",
    "                c = p[-1].get_color()\n",
    "                ax2.plot(np.argmax(log[metric_type + key]), np.amax(log[metric_type + key]), \n",
    "                         '*', markersize=10, alpha=0.5, color=c)\n",
    "                ax2.set_title('max val acc: {0:.2f}'.format(np.amax(log['val_' + key]*100)))\n",
    "                ax2.set_ylabel('accuracy')\n",
    "                ax2.set_xlabel('epochs')\n",
    "    ax1.grid()\n",
    "    ax2.grid()\n",
    "    ax1.legend()\n",
    "    ax2.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for index, model_id in enumerate(range(17, 17+n_models)):\n",
    "    model_folder = os.path.join(output_baseline_folder, str(model_id))\n",
    "    test_pred_path = os.path.join(model_folder, 'test_pred.npy')\n",
    "    # if True:\n",
    "    if not os.path.isfile(test_pred_path):\n",
    "        checkpoint_path = glob.glob( model_folder + '/weights.' + str(epochs).zfill(2) + '*.hdf5')[0]\n",
    "        model = cnn()\n",
    "        print('loading weights for model {}...'.format(model_id))\n",
    "        model.load_weights(checkpoint_path)\n",
    "        print('inference...')\n",
    "        test_pred = model.predict(x_test)\n",
    "        np.save(test_pred_path, test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_model_id = 17\n",
    "y_pred_sample = np.load(os.path.join(output_baseline_folder, str(sample_model_id), 'test_pred.npy'))\n",
    "shape = np.shape(y_pred_sample)\n",
    "all_test_preds = np.zeros((n_models, *shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = []\n",
    "for index, model_id in enumerate(range(17, 17+n_models)):\n",
    "    y_pred = np.load(os.path.join(output_baseline_folder, str(model_id), 'test_pred.npy'))\n",
    "    all_test_preds[index] = y_pred\n",
    "    nll = log_loss(y_test, y_pred)\n",
    "    error = classification_error(y_test, y_pred)\n",
    "    br = brier_multi(y_test, y_pred)\n",
    "    calib_erros = CalibrationErrors(y_test, y_pred, bin_size=1 / 20., min_samples=0)\n",
    "    _, _, ece, mce, _ = calib_erros.calculate_calibration_errors()\n",
    "    d.append(OrderedDict({\"model\":model_id, \"nll\": nll, \"brier\": br, \"ece\": ece, \"mce\":mce, \"classification error\": error}))\n",
    "df_baselines = pd.DataFrame(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>nll</th>\n",
       "      <th>brier</th>\n",
       "      <th>ece</th>\n",
       "      <th>mce</th>\n",
       "      <th>classification error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>0.036594</td>\n",
       "      <td>0.014640</td>\n",
       "      <td>0.507882</td>\n",
       "      <td>47.358504</td>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>0.036924</td>\n",
       "      <td>0.016234</td>\n",
       "      <td>0.570997</td>\n",
       "      <td>32.696912</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>0.029432</td>\n",
       "      <td>0.012960</td>\n",
       "      <td>0.465574</td>\n",
       "      <td>68.628386</td>\n",
       "      <td>0.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>0.040010</td>\n",
       "      <td>0.016554</td>\n",
       "      <td>0.588962</td>\n",
       "      <td>47.255030</td>\n",
       "      <td>1.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>21</td>\n",
       "      <td>0.032994</td>\n",
       "      <td>0.014503</td>\n",
       "      <td>0.461238</td>\n",
       "      <td>36.594246</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>22</td>\n",
       "      <td>0.032003</td>\n",
       "      <td>0.013860</td>\n",
       "      <td>0.487419</td>\n",
       "      <td>57.566917</td>\n",
       "      <td>0.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>23</td>\n",
       "      <td>0.043686</td>\n",
       "      <td>0.020463</td>\n",
       "      <td>0.628043</td>\n",
       "      <td>38.309494</td>\n",
       "      <td>1.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>24</td>\n",
       "      <td>0.032765</td>\n",
       "      <td>0.014113</td>\n",
       "      <td>0.465772</td>\n",
       "      <td>47.748852</td>\n",
       "      <td>0.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>25</td>\n",
       "      <td>0.043138</td>\n",
       "      <td>0.017843</td>\n",
       "      <td>0.630829</td>\n",
       "      <td>66.212824</td>\n",
       "      <td>1.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>26</td>\n",
       "      <td>0.032941</td>\n",
       "      <td>0.013969</td>\n",
       "      <td>0.453493</td>\n",
       "      <td>42.323929</td>\n",
       "      <td>0.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>27</td>\n",
       "      <td>0.045014</td>\n",
       "      <td>0.018772</td>\n",
       "      <td>0.672164</td>\n",
       "      <td>67.879033</td>\n",
       "      <td>1.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>28</td>\n",
       "      <td>0.031583</td>\n",
       "      <td>0.014058</td>\n",
       "      <td>0.467160</td>\n",
       "      <td>65.121147</td>\n",
       "      <td>0.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>29</td>\n",
       "      <td>0.039164</td>\n",
       "      <td>0.017390</td>\n",
       "      <td>0.595902</td>\n",
       "      <td>33.408147</td>\n",
       "      <td>1.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>30</td>\n",
       "      <td>0.033827</td>\n",
       "      <td>0.015065</td>\n",
       "      <td>0.531555</td>\n",
       "      <td>25.626532</td>\n",
       "      <td>0.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>31</td>\n",
       "      <td>0.036046</td>\n",
       "      <td>0.017045</td>\n",
       "      <td>0.532439</td>\n",
       "      <td>60.920539</td>\n",
       "      <td>1.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>32</td>\n",
       "      <td>0.033826</td>\n",
       "      <td>0.014421</td>\n",
       "      <td>0.427100</td>\n",
       "      <td>27.253083</td>\n",
       "      <td>0.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>33</td>\n",
       "      <td>0.042874</td>\n",
       "      <td>0.018613</td>\n",
       "      <td>0.522411</td>\n",
       "      <td>41.918090</td>\n",
       "      <td>1.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>34</td>\n",
       "      <td>0.039827</td>\n",
       "      <td>0.017176</td>\n",
       "      <td>0.551191</td>\n",
       "      <td>28.976530</td>\n",
       "      <td>1.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>35</td>\n",
       "      <td>0.038397</td>\n",
       "      <td>0.017209</td>\n",
       "      <td>0.599109</td>\n",
       "      <td>63.781095</td>\n",
       "      <td>1.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>36</td>\n",
       "      <td>0.031455</td>\n",
       "      <td>0.013952</td>\n",
       "      <td>0.438012</td>\n",
       "      <td>65.196034</td>\n",
       "      <td>0.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>37</td>\n",
       "      <td>0.031163</td>\n",
       "      <td>0.013927</td>\n",
       "      <td>0.451603</td>\n",
       "      <td>58.785945</td>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>38</td>\n",
       "      <td>0.032075</td>\n",
       "      <td>0.013733</td>\n",
       "      <td>0.394043</td>\n",
       "      <td>47.569683</td>\n",
       "      <td>0.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>39</td>\n",
       "      <td>0.033594</td>\n",
       "      <td>0.014206</td>\n",
       "      <td>0.420996</td>\n",
       "      <td>49.390641</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>40</td>\n",
       "      <td>0.038689</td>\n",
       "      <td>0.016588</td>\n",
       "      <td>0.523693</td>\n",
       "      <td>36.894244</td>\n",
       "      <td>1.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>41</td>\n",
       "      <td>0.033702</td>\n",
       "      <td>0.014831</td>\n",
       "      <td>0.528490</td>\n",
       "      <td>48.907596</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    model       nll     brier       ece        mce  classification error\n",
       "0      17  0.036594  0.014640  0.507882  47.358504                  0.90\n",
       "1      18  0.036924  0.016234  0.570997  32.696912                  0.98\n",
       "2      19  0.029432  0.012960  0.465574  68.628386                  0.81\n",
       "3      20  0.040010  0.016554  0.588962  47.255030                  1.02\n",
       "4      21  0.032994  0.014503  0.461238  36.594246                  0.92\n",
       "5      22  0.032003  0.013860  0.487419  57.566917                  0.85\n",
       "6      23  0.043686  0.020463  0.628043  38.309494                  1.36\n",
       "7      24  0.032765  0.014113  0.465772  47.748852                  0.89\n",
       "8      25  0.043138  0.017843  0.630829  66.212824                  1.15\n",
       "9      26  0.032941  0.013969  0.453493  42.323929                  0.86\n",
       "10     27  0.045014  0.018772  0.672164  67.879033                  1.13\n",
       "11     28  0.031583  0.014058  0.467160  65.121147                  0.89\n",
       "12     29  0.039164  0.017390  0.595902  33.408147                  1.11\n",
       "13     30  0.033827  0.015065  0.531555  25.626532                  0.96\n",
       "14     31  0.036046  0.017045  0.532439  60.920539                  1.07\n",
       "15     32  0.033826  0.014421  0.427100  27.253083                  0.88\n",
       "16     33  0.042874  0.018613  0.522411  41.918090                  1.21\n",
       "17     34  0.039827  0.017176  0.551191  28.976530                  1.11\n",
       "18     35  0.038397  0.017209  0.599109  63.781095                  1.10\n",
       "19     36  0.031455  0.013952  0.438012  65.196034                  0.88\n",
       "20     37  0.031163  0.013927  0.451603  58.785945                  0.90\n",
       "21     38  0.032075  0.013733  0.394043  47.569683                  0.86\n",
       "22     39  0.033594  0.014206  0.420996  49.390641                  0.92\n",
       "23     40  0.038689  0.016588  0.523693  36.894244                  1.08\n",
       "24     41  0.033702  0.014831  0.528490  48.907596                  0.92"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BASELINE RESULTS (TEST SET)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "NLL\n",
      "0.036 ± 0.00\n",
      "--------------------\n",
      "BRIER\n",
      "0.016 ± 0.00\n",
      "--------------------\n",
      "ECE\n",
      "0.517 ± 0.07\n",
      "--------------------\n",
      "MCE\n",
      "48.253 ± 13.45\n",
      "--------------------\n",
      "CLASSIFICATION ERROR\n",
      "0.990 ± 0.13\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "print('Baseline Results (test set)'.upper())\n",
    "print('-'*100)\n",
    "metrics = ['nll', 'brier', 'ece', 'mce', 'classification error']\n",
    "for metric in metrics:\n",
    "    print('{0}'.format(metric.upper()))\n",
    "    print('{0:.3f} \\u00B1 {1:.2f}'.format(np.mean(df_baselines[metric]), np.std(df_baselines[metric])))\n",
    "    print('-'*20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Ensembles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO: Increase number of models and do bootstrapping for DE to provide std..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_bootstrap = 100\n",
    "m_deep_ensemble = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = []\n",
    "for i in range(n_bootstrap):\n",
    "    model_indices = np.random.choice(np.shape(all_test_preds)[0], size=m_deep_ensemble, replace=False)\n",
    "    y_pred = np.mean(np.stack(all_test_preds[model_indices], axis=0), axis=0)\n",
    "    nll = log_loss(y_test, y_pred)\n",
    "    error = classification_error(y_test, y_pred)\n",
    "    br = brier_multi(y_test, y_pred)\n",
    "    calib_erros = CalibrationErrors(y_test, y_pred, bin_size=1 / 20., min_samples=0)\n",
    "    _, _, ece, mce, _ = calib_erros.calculate_calibration_errors()\n",
    "    d.append(OrderedDict({\"model\":model_id, \"nll\": nll, \"brier\": br, \"ece\": ece, \"mce\":mce, \"classification error\": error}))\n",
    "df_deep_ensembles = pd.DataFrame(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>nll</th>\n",
       "      <th>brier</th>\n",
       "      <th>ece</th>\n",
       "      <th>mce</th>\n",
       "      <th>classification error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>0.020074</td>\n",
       "      <td>0.010073</td>\n",
       "      <td>0.246266</td>\n",
       "      <td>13.732367</td>\n",
       "      <td>0.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>0.020573</td>\n",
       "      <td>0.010293</td>\n",
       "      <td>0.293423</td>\n",
       "      <td>35.811099</td>\n",
       "      <td>0.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>41</td>\n",
       "      <td>0.020677</td>\n",
       "      <td>0.010444</td>\n",
       "      <td>0.268155</td>\n",
       "      <td>31.345645</td>\n",
       "      <td>0.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>41</td>\n",
       "      <td>0.020650</td>\n",
       "      <td>0.010076</td>\n",
       "      <td>0.288076</td>\n",
       "      <td>31.317680</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>41</td>\n",
       "      <td>0.020548</td>\n",
       "      <td>0.010576</td>\n",
       "      <td>0.231962</td>\n",
       "      <td>69.357126</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95</td>\n",
       "      <td>41</td>\n",
       "      <td>0.020564</td>\n",
       "      <td>0.010060</td>\n",
       "      <td>0.258543</td>\n",
       "      <td>36.640974</td>\n",
       "      <td>0.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96</td>\n",
       "      <td>41</td>\n",
       "      <td>0.020186</td>\n",
       "      <td>0.010072</td>\n",
       "      <td>0.225385</td>\n",
       "      <td>55.817862</td>\n",
       "      <td>0.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>97</td>\n",
       "      <td>41</td>\n",
       "      <td>0.021173</td>\n",
       "      <td>0.010597</td>\n",
       "      <td>0.212465</td>\n",
       "      <td>69.458918</td>\n",
       "      <td>0.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>98</td>\n",
       "      <td>41</td>\n",
       "      <td>0.021475</td>\n",
       "      <td>0.010398</td>\n",
       "      <td>0.369450</td>\n",
       "      <td>32.932890</td>\n",
       "      <td>0.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>99</td>\n",
       "      <td>41</td>\n",
       "      <td>0.020726</td>\n",
       "      <td>0.010244</td>\n",
       "      <td>0.227749</td>\n",
       "      <td>66.306331</td>\n",
       "      <td>0.63</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    model       nll     brier       ece        mce  classification error\n",
       "0      41  0.020074  0.010073  0.246266  13.732367                  0.68\n",
       "1      41  0.020573  0.010293  0.293423  35.811099                  0.67\n",
       "2      41  0.020677  0.010444  0.268155  31.345645                  0.67\n",
       "3      41  0.020650  0.010076  0.288076  31.317680                  0.72\n",
       "4      41  0.020548  0.010576  0.231962  69.357126                  0.72\n",
       "..    ...       ...       ...       ...        ...                   ...\n",
       "95     41  0.020564  0.010060  0.258543  36.640974                  0.68\n",
       "96     41  0.020186  0.010072  0.225385  55.817862                  0.62\n",
       "97     41  0.021173  0.010597  0.212465  69.458918                  0.67\n",
       "98     41  0.021475  0.010398  0.369450  32.932890                  0.62\n",
       "99     41  0.020726  0.010244  0.227749  66.306331                  0.63\n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_deep_ensembles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEEP ENSEMBLE RESULTS (TEST SET)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "NLL\n",
      "0.021 ± 0.00\n",
      "--------------------\n",
      "BRIER\n",
      "0.010 ± 0.00\n",
      "--------------------\n",
      "ECE\n",
      "0.288 ± 0.05\n",
      "--------------------\n",
      "MCE\n",
      "44.856 ± 17.03\n",
      "--------------------\n",
      "CLASSIFICATION ERROR\n",
      "0.661 ± 0.03\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "print('Deep Ensemble Results (test set)'.upper())\n",
    "print('-'*100)\n",
    "metrics = ['nll', 'brier', 'ece', 'mce', 'classification error']\n",
    "for metric in metrics:\n",
    "    print('{0}'.format(metric.upper()))\n",
    "    print('{0:.3f} \\u00B1 {1:.2f}'.format(np.mean(df_deep_ensembles[metric]), np.std(df_deep_ensembles[metric])))\n",
    "    print('-'*20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Temperature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "def softmax_t(y_logit, t):\n",
    "    return np.exp(y_logit/t)/np.sum(np.exp(y_logit/t), axis=-1)[:, np.newaxis]\n",
    "\n",
    "\n",
    "def ll_t(t):\n",
    "    y_val_pred = model.predict(x_val)\n",
    "    y_pred_base_logit = np.log(y_val_pred)\n",
    "    y_pred_temp = softmax_t(y_pred_base_logit, t)\n",
    "    ll = log_loss(y_val, y_pred_temp)\n",
    "    return ll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.55223098]\n",
      " [1.53834358]\n",
      " [1.4973783 ]\n",
      " [1.45628722]\n",
      " [1.46255998]\n",
      " [1.54153129]\n",
      " [1.3807363 ]\n",
      " [1.56610639]\n",
      " [1.48526209]\n",
      " [1.47919712]\n",
      " [1.54502638]\n",
      " [1.40658667]\n",
      " [1.52610853]\n",
      " [1.54012705]\n",
      " [1.47425313]\n",
      " [1.4919964 ]\n",
      " [1.45173708]\n",
      " [1.52414143]\n",
      " [1.60419805]\n",
      " [1.50656317]\n",
      " [1.48144516]\n",
      " [1.44980195]\n",
      " [1.5177191 ]\n",
      " [1.47435017]\n",
      " [1.47740948]]\n"
     ]
    }
   ],
   "source": [
    "optimal_temps = []\n",
    "optimal_temps_path = os.path.join(output_baseline_folder, 'optimal_temps.csv')\n",
    "if not os.path.isfile(optimal_temps_path):\n",
    "# if True:\n",
    "    for index, model_id in enumerate(range(17, 17+ n_models)):\n",
    "        print('finding optimal sigma for model {}...'.format(model_id))\n",
    "        model_folder = os.path.join(output_baseline_folder, str(model_id))\n",
    "        checkpoint_path = glob.glob( model_folder + '/weights.' + str(epochs).zfill(2) + '*.hdf5')[0]\n",
    "        model = cnn()\n",
    "        print('loading weights...')\n",
    "        model.load_weights(checkpoint_path)\n",
    "        print('running optimization...')\n",
    "        xopt = minimize(ll_t, 1, method='bfgs', options={'disp': 1})\n",
    "        optimal_temp = xopt['x'][0]\n",
    "        print('-'*100)\n",
    "        print(model_id, optimal_temp)\n",
    "        optimal_temps.append(optimal_temp)\n",
    "    pd.DataFrame(optimal_temps, columns=['optimal temp']).to_csv(optimal_temps_path, index=False)\n",
    "else:\n",
    "    optimal_temps = pd.read_csv(optimal_temps_path).values\n",
    "print(optimal_temps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, model_id in enumerate(range(17, 17 + n_models)):\n",
    "    model_folder = os.path.join(output_baseline_folder, str(model_id))\n",
    "    output_ts_folder = os.path.join(model_folder, 'temp_scaled')\n",
    "    if not os.path.isdir(output_ts_folder):\n",
    "        os.mkdir(output_ts_folder)\n",
    "    y_pred = np.load(os.path.join(model_folder, 'test_pred.npy'))\n",
    "    optimal_temp = optimal_temps[index]\n",
    "    #\n",
    "    y_pred_logit = np.log(y_pred)\n",
    "    y_pred_ts = softmax_t(y_pred_logit, t=optimal_temp)\n",
    "    #\n",
    "    np.save(os.path.join(output_ts_folder, 'test_pred_ts.npy'), y_pred_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = list()\n",
    "for index, model_id in enumerate(range(17, 17 + n_models)):\n",
    "    model_ppe_folder= os.path.join(output_baseline_folder, str(model_id),  'temp_scaled')\n",
    "    y_pred = np.load(os.path.join(model_ppe_folder, 'test_pred_ts.npy'))\n",
    "    nll = log_loss(y_test, y_pred)\n",
    "    error = classification_error(y_test, y_pred)\n",
    "    br = brier_multi(y_test, y_pred)\n",
    "    calib_erros = CalibrationErrors(y_test, y_pred, bin_size=1 / 20., min_samples=0)\n",
    "    _, _, ece, mce, _ = calib_erros.calculate_calibration_errors()\n",
    "    d.append(OrderedDict({\"model\":model_id, \"nll\": nll, \"brier\": br, \"ece\": ece, \"mce\":mce, \"classification error\": error}))\n",
    "df_ts= pd.DataFrame(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>nll</th>\n",
       "      <th>brier</th>\n",
       "      <th>ece</th>\n",
       "      <th>mce</th>\n",
       "      <th>classification error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>0.031236</td>\n",
       "      <td>0.014191</td>\n",
       "      <td>0.227599</td>\n",
       "      <td>36.864736</td>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>0.032029</td>\n",
       "      <td>0.015551</td>\n",
       "      <td>0.276222</td>\n",
       "      <td>46.762324</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>0.025831</td>\n",
       "      <td>0.012337</td>\n",
       "      <td>0.215158</td>\n",
       "      <td>73.471432</td>\n",
       "      <td>0.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>0.034956</td>\n",
       "      <td>0.016178</td>\n",
       "      <td>0.199902</td>\n",
       "      <td>43.026470</td>\n",
       "      <td>1.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>21</td>\n",
       "      <td>0.029568</td>\n",
       "      <td>0.013980</td>\n",
       "      <td>0.227437</td>\n",
       "      <td>42.098110</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>22</td>\n",
       "      <td>0.028597</td>\n",
       "      <td>0.013493</td>\n",
       "      <td>0.192260</td>\n",
       "      <td>66.670550</td>\n",
       "      <td>0.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>23</td>\n",
       "      <td>0.040633</td>\n",
       "      <td>0.019859</td>\n",
       "      <td>0.339063</td>\n",
       "      <td>35.075896</td>\n",
       "      <td>1.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>24</td>\n",
       "      <td>0.029155</td>\n",
       "      <td>0.013422</td>\n",
       "      <td>0.225140</td>\n",
       "      <td>33.657393</td>\n",
       "      <td>0.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>25</td>\n",
       "      <td>0.036750</td>\n",
       "      <td>0.017061</td>\n",
       "      <td>0.248283</td>\n",
       "      <td>71.363016</td>\n",
       "      <td>1.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>26</td>\n",
       "      <td>0.029013</td>\n",
       "      <td>0.013458</td>\n",
       "      <td>0.167293</td>\n",
       "      <td>37.653620</td>\n",
       "      <td>0.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>27</td>\n",
       "      <td>0.039017</td>\n",
       "      <td>0.018213</td>\n",
       "      <td>0.379749</td>\n",
       "      <td>71.013124</td>\n",
       "      <td>1.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>28</td>\n",
       "      <td>0.028517</td>\n",
       "      <td>0.013664</td>\n",
       "      <td>0.242271</td>\n",
       "      <td>70.218556</td>\n",
       "      <td>0.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>29</td>\n",
       "      <td>0.034061</td>\n",
       "      <td>0.016575</td>\n",
       "      <td>0.235225</td>\n",
       "      <td>29.728109</td>\n",
       "      <td>1.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>30</td>\n",
       "      <td>0.029564</td>\n",
       "      <td>0.014244</td>\n",
       "      <td>0.317231</td>\n",
       "      <td>42.769317</td>\n",
       "      <td>0.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>31</td>\n",
       "      <td>0.033196</td>\n",
       "      <td>0.016407</td>\n",
       "      <td>0.290726</td>\n",
       "      <td>65.763738</td>\n",
       "      <td>1.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>32</td>\n",
       "      <td>0.030373</td>\n",
       "      <td>0.014207</td>\n",
       "      <td>0.212370</td>\n",
       "      <td>43.419476</td>\n",
       "      <td>0.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>33</td>\n",
       "      <td>0.038561</td>\n",
       "      <td>0.018150</td>\n",
       "      <td>0.317335</td>\n",
       "      <td>38.467054</td>\n",
       "      <td>1.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>34</td>\n",
       "      <td>0.034786</td>\n",
       "      <td>0.016469</td>\n",
       "      <td>0.348674</td>\n",
       "      <td>29.964904</td>\n",
       "      <td>1.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>35</td>\n",
       "      <td>0.033855</td>\n",
       "      <td>0.016304</td>\n",
       "      <td>0.381573</td>\n",
       "      <td>34.132523</td>\n",
       "      <td>1.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>36</td>\n",
       "      <td>0.028520</td>\n",
       "      <td>0.013509</td>\n",
       "      <td>0.276077</td>\n",
       "      <td>32.511522</td>\n",
       "      <td>0.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>37</td>\n",
       "      <td>0.027849</td>\n",
       "      <td>0.013405</td>\n",
       "      <td>0.245197</td>\n",
       "      <td>64.987746</td>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>38</td>\n",
       "      <td>0.029339</td>\n",
       "      <td>0.013577</td>\n",
       "      <td>0.237075</td>\n",
       "      <td>28.841229</td>\n",
       "      <td>0.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>39</td>\n",
       "      <td>0.030368</td>\n",
       "      <td>0.013869</td>\n",
       "      <td>0.254700</td>\n",
       "      <td>27.575286</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>40</td>\n",
       "      <td>0.034463</td>\n",
       "      <td>0.016036</td>\n",
       "      <td>0.235463</td>\n",
       "      <td>32.533214</td>\n",
       "      <td>1.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>41</td>\n",
       "      <td>0.029453</td>\n",
       "      <td>0.014251</td>\n",
       "      <td>0.188539</td>\n",
       "      <td>37.830746</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    model       nll     brier       ece        mce  classification error\n",
       "0      17  0.031236  0.014191  0.227599  36.864736                  0.90\n",
       "1      18  0.032029  0.015551  0.276222  46.762324                  0.98\n",
       "2      19  0.025831  0.012337  0.215158  73.471432                  0.81\n",
       "3      20  0.034956  0.016178  0.199902  43.026470                  1.02\n",
       "4      21  0.029568  0.013980  0.227437  42.098110                  0.92\n",
       "5      22  0.028597  0.013493  0.192260  66.670550                  0.85\n",
       "6      23  0.040633  0.019859  0.339063  35.075896                  1.36\n",
       "7      24  0.029155  0.013422  0.225140  33.657393                  0.89\n",
       "8      25  0.036750  0.017061  0.248283  71.363016                  1.15\n",
       "9      26  0.029013  0.013458  0.167293  37.653620                  0.86\n",
       "10     27  0.039017  0.018213  0.379749  71.013124                  1.13\n",
       "11     28  0.028517  0.013664  0.242271  70.218556                  0.89\n",
       "12     29  0.034061  0.016575  0.235225  29.728109                  1.11\n",
       "13     30  0.029564  0.014244  0.317231  42.769317                  0.96\n",
       "14     31  0.033196  0.016407  0.290726  65.763738                  1.07\n",
       "15     32  0.030373  0.014207  0.212370  43.419476                  0.88\n",
       "16     33  0.038561  0.018150  0.317335  38.467054                  1.21\n",
       "17     34  0.034786  0.016469  0.348674  29.964904                  1.11\n",
       "18     35  0.033855  0.016304  0.381573  34.132523                  1.10\n",
       "19     36  0.028520  0.013509  0.276077  32.511522                  0.88\n",
       "20     37  0.027849  0.013405  0.245197  64.987746                  0.90\n",
       "21     38  0.029339  0.013577  0.237075  28.841229                  0.86\n",
       "22     39  0.030368  0.013869  0.254700  27.575286                  0.92\n",
       "23     40  0.034463  0.016036  0.235463  32.533214                  1.08\n",
       "24     41  0.029453  0.014251  0.188539  37.830746                  0.92"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEMPERATURE SCALING RESULTS (TEST SET)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "NLL\n",
      "0.032 ± 0.00\n",
      "--------------------\n",
      "BRIER\n",
      "0.015 ± 0.00\n",
      "--------------------\n",
      "ECE\n",
      "0.259 ± 0.06\n",
      "--------------------\n",
      "MCE\n",
      "45.456 ± 15.53\n",
      "--------------------\n",
      "CLASSIFICATION ERROR\n",
      "0.990 ± 0.13\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "print('Temperature Scaling Results (test set)'.upper())\n",
    "print('-'*100)\n",
    "metrics = ['nll', 'brier', 'ece', 'mce', 'classification error']\n",
    "for metric in metrics:\n",
    "    print('{0}'.format(metric.upper()))\n",
    "    print('{0:.3f} \\u00B1 {1:.2f}'.format(np.mean(df_ts[metric]), np.std(df_ts[metric])))\n",
    "    print('-'*20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PPE:\n",
    "    def __init__(self, model, n_ensemble):\n",
    "        self.model = model\n",
    "        self.n_ensemble = n_ensemble\n",
    "        self.original_weights = model.get_weights()\n",
    "        \n",
    "    def perturb(self, sigma):\n",
    "        self.model.set_weights(self.original_weights)\n",
    "        weights = self.model.get_weights()\n",
    "        for index2, w in enumerate(weights):\n",
    "            shape = w.shape\n",
    "            if len(shape) >= 2  and shape[-1] > 32:\n",
    "                if len(shape) == 4:\n",
    "                    noise = np.random.normal(0, sigma, (w.shape[0], w.shape[1], w.shape[2], w.shape[3]))\n",
    "                else:\n",
    "                    noise = np.random.normal(0, sigma, (w.shape[0], w.shape[1]))\n",
    "                weights[index2] = weights[index2] + noise\n",
    "        self.model.set_weights(weights)\n",
    "    \n",
    "    def ensemble_pred(self, x, sigma):\n",
    "        y_pred = self.model.predict(x)\n",
    "        y_pred_ensemble = np.zeros((self.n_ensemble, *y_pred.shape))\n",
    "        for seed_index, seed in enumerate(range(17, 17 + self.n_ensemble)):\n",
    "            np.random.seed(seed)\n",
    "            self.perturb(sigma)\n",
    "            y_pred = self.model.predict(x)\n",
    "            y_pred_ensemble[seed_index] = y_pred\n",
    "        self.model.set_weights(self.original_weights)\n",
    "        return np.mean(y_pred_ensemble, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def golden_search(model, sigma_lower=0, sigma_upper=0.1, n_ppe_ensemble=5, n_iterations=10):\n",
    "    sigmas_log = list()\n",
    "    nlls_log = list()\n",
    "    nlls = dict()\n",
    "    PHI = (np.sqrt(5) - 1) / 2\n",
    "    for iteration in range(n_iterations):\n",
    "        print('iteration {} {} {} '.format(iteration, sigma_lower, sigma_upper) + '-'* 10)\n",
    "        sigma_1 = sigma_lower + (sigma_upper - sigma_lower) * PHI\n",
    "        sigma_2 = sigma_lower + (sigma_1 - sigma_lower) * PHI\n",
    "        sigmas_log.append(OrderedDict({\"iteration\": iteration, \"sigma_l\": sigma_lower,\n",
    "                                       \"sigma_2\": sigma_2, \"sigma_1\": sigma_1,\n",
    "                                       \"sigma_h\": sigma_upper}))\n",
    "        for sigma in [sigma_1, sigma_2]:\n",
    "            if sigma not in nlls.keys():\n",
    "                ppe = PPE(model, n_ensemble=n_ppe_ensemble)\n",
    "                y_val_ppe = ppe.ensemble_pred(x_val, sigma)\n",
    "                nll = log_loss(y_val, y_val_ppe)\n",
    "                nlls[sigma] = nll\n",
    "                print(sigma, nll)\n",
    "                nlls_log.append(OrderedDict({\"iteration\": iteration, \"sigma\": sigma, \"nll\": nll}))\n",
    "            else:\n",
    "                print('will skip for {0:6f}'.format(sigma))\n",
    "        if nlls[sigma_1] < nlls[sigma_2]:\n",
    "            sigma_lower = sigma_2\n",
    "            print('updated lower side...')\n",
    "        else:\n",
    "            sigma_upper = sigma_1\n",
    "            print('updated upper side...')\n",
    "    sigma_optimal = (sigmas_log[-1]['sigma_l'] + sigmas_log[-1]['sigma_h'])/2\n",
    "    return sigma_optimal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.01656315 0.01818927 0.01261646 0.01524758 0.01311896 0.01737621\n",
      " 0.01606065 0.01443452 0.01606065 0.01443452 0.01393202 0.00410197\n",
      " 0.01737621 0.01393202 0.01737621 0.01656315 0.01656315 0.01524758\n",
      " 0.00917228 0.02082039 0.01656315 0.01524758 0.01869177 0.01443452\n",
      " 0.01524758]\n"
     ]
    }
   ],
   "source": [
    "optimal_sigmas = []\n",
    "optimal_sigmas_path = os.path.join(output_baseline_folder, 'golden_optimization_simgas.csv')\n",
    "if not os.path.isfile(optimal_sigmas_path):\n",
    "    for index, model_id in enumerate(range(17, 17 + n_models)):\n",
    "        print('finding optimal sigma for model {}...'.format(model_id))\n",
    "        model_folder = os.path.join(output_baseline_folder, str(model_id))\n",
    "        checkpoint_path = glob.glob( model_folder + '/weights.' + str(epochs).zfill(2) + '*.hdf5')[0]\n",
    "        model = cnn()\n",
    "        print('loading weights...')\n",
    "        model.load_weights(checkpoint_path)\n",
    "        print('running optimization...')\n",
    "        optimal_sigma = golden_search(model)\n",
    "        optimal_sigmas.append(optimal_sigma)\n",
    "    df = pd.DataFrame(optimal_sigmas, columns=['optimal sigma'])\n",
    "    df.to_csv(optimal_sigmas_path, index=False)\n",
    "else:\n",
    "    df = pd.read_csv(optimal_sigmas_path)\n",
    "optimal_sigmas = df['optimal sigma'].values\n",
    "print(optimal_sigmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.01656315 0.01818927 0.01261646 0.01524758 0.01311896 0.01737621\n",
      " 0.01606065 0.01443452 0.01606065 0.01443452 0.01393202 0.00410197\n",
      " 0.01737621 0.01393202 0.01737621 0.01656315 0.01656315 0.01524758\n",
      " 0.00917228 0.02082039 0.01656315 0.01524758 0.01869177 0.01443452\n",
      " 0.01524758]\n"
     ]
    }
   ],
   "source": [
    "print(optimal_sigmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_ppe_ensemble = 25\n",
    "for index, model_id in enumerate(range(17, 17+n_models)):\n",
    "    model_folder = os.path.join(output_baseline_folder, str(model_id))\n",
    "    output_ppe_folder = os.path.join(model_folder, 'ppe')\n",
    "    if not os.path.isdir(output_ppe_folder):\n",
    "        os.mkdir(output_ppe_folder)\n",
    "    test_pred_path = os.path.join(output_ppe_folder, 'test_pred_ppe.npy')\n",
    "    if not os.path.isfile(test_pred_path):\n",
    "    # if True:\n",
    "        checkpoint_path = glob.glob(model_folder + '/weights.' + str(epochs).zfill(2) + '*.hdf5')[0]\n",
    "        model = cnn()\n",
    "        print('loading weights for model {}...'.format(model_id))\n",
    "        model.load_weights(checkpoint_path)\n",
    "        optimal_sigma = optimal_sigmas[index]\n",
    "        ppe = PPE(model, n_ensemble=n_ppe_ensemble)\n",
    "        y_pred = ppe.ensemble_pred(x_test, optimal_sigma)\n",
    "        np.save(test_pred_path, y_pred)\n",
    "    else:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = list()\n",
    "for index, model_id in enumerate(range(17, 17 + n_models)):\n",
    "    model_ppe_folder= os.path.join(output_baseline_folder, str(model_id),  'ppe')\n",
    "    y_pred = np.load(os.path.join(model_ppe_folder, 'test_pred_ppe.npy'))\n",
    "    nll = log_loss(y_test, y_pred)\n",
    "    error = classification_error(y_test, y_pred)\n",
    "    br = brier_multi(y_test, y_pred)\n",
    "    calib_erros = CalibrationErrors(y_test, y_pred, bin_size=1 / 20., min_samples=0)\n",
    "    _, _, ece, mce, _ = calib_erros.calculate_calibration_errors()\n",
    "    d.append(OrderedDict({\"model\":model_id, \"nll\": nll, \"brier\": br, \"ece\": ece, \"mce\":mce, \"classification error\": error}))\n",
    "df_ppe = pd.DataFrame(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>nll</th>\n",
       "      <th>brier</th>\n",
       "      <th>ece</th>\n",
       "      <th>mce</th>\n",
       "      <th>classification error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>0.032864</td>\n",
       "      <td>0.014360</td>\n",
       "      <td>0.407820</td>\n",
       "      <td>26.800570</td>\n",
       "      <td>0.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>0.033854</td>\n",
       "      <td>0.016187</td>\n",
       "      <td>0.383372</td>\n",
       "      <td>17.783421</td>\n",
       "      <td>1.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>0.026642</td>\n",
       "      <td>0.012424</td>\n",
       "      <td>0.364157</td>\n",
       "      <td>67.611680</td>\n",
       "      <td>0.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>0.038028</td>\n",
       "      <td>0.016371</td>\n",
       "      <td>0.484884</td>\n",
       "      <td>52.044736</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>21</td>\n",
       "      <td>0.031545</td>\n",
       "      <td>0.014283</td>\n",
       "      <td>0.395764</td>\n",
       "      <td>63.523687</td>\n",
       "      <td>0.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>22</td>\n",
       "      <td>0.029846</td>\n",
       "      <td>0.013624</td>\n",
       "      <td>0.256253</td>\n",
       "      <td>70.088703</td>\n",
       "      <td>0.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>23</td>\n",
       "      <td>0.040455</td>\n",
       "      <td>0.019717</td>\n",
       "      <td>0.303081</td>\n",
       "      <td>27.208157</td>\n",
       "      <td>1.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>24</td>\n",
       "      <td>0.030986</td>\n",
       "      <td>0.013966</td>\n",
       "      <td>0.319389</td>\n",
       "      <td>26.643641</td>\n",
       "      <td>0.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>25</td>\n",
       "      <td>0.039387</td>\n",
       "      <td>0.016895</td>\n",
       "      <td>0.399911</td>\n",
       "      <td>70.433485</td>\n",
       "      <td>1.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>26</td>\n",
       "      <td>0.030352</td>\n",
       "      <td>0.013360</td>\n",
       "      <td>0.304104</td>\n",
       "      <td>30.806845</td>\n",
       "      <td>0.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>27</td>\n",
       "      <td>0.042083</td>\n",
       "      <td>0.018238</td>\n",
       "      <td>0.521044</td>\n",
       "      <td>74.650011</td>\n",
       "      <td>1.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>28</td>\n",
       "      <td>0.030872</td>\n",
       "      <td>0.014010</td>\n",
       "      <td>0.471211</td>\n",
       "      <td>66.532917</td>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>29</td>\n",
       "      <td>0.035260</td>\n",
       "      <td>0.016887</td>\n",
       "      <td>0.330447</td>\n",
       "      <td>33.671738</td>\n",
       "      <td>1.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>30</td>\n",
       "      <td>0.031338</td>\n",
       "      <td>0.014635</td>\n",
       "      <td>0.435284</td>\n",
       "      <td>32.694436</td>\n",
       "      <td>0.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>31</td>\n",
       "      <td>0.034491</td>\n",
       "      <td>0.016913</td>\n",
       "      <td>0.279106</td>\n",
       "      <td>13.928951</td>\n",
       "      <td>1.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>32</td>\n",
       "      <td>0.031556</td>\n",
       "      <td>0.014473</td>\n",
       "      <td>0.356103</td>\n",
       "      <td>58.299924</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>33</td>\n",
       "      <td>0.041040</td>\n",
       "      <td>0.018445</td>\n",
       "      <td>0.358367</td>\n",
       "      <td>38.110917</td>\n",
       "      <td>1.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>34</td>\n",
       "      <td>0.037229</td>\n",
       "      <td>0.016927</td>\n",
       "      <td>0.352752</td>\n",
       "      <td>66.641052</td>\n",
       "      <td>1.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>35</td>\n",
       "      <td>0.036809</td>\n",
       "      <td>0.016937</td>\n",
       "      <td>0.512715</td>\n",
       "      <td>19.586023</td>\n",
       "      <td>1.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>36</td>\n",
       "      <td>0.029288</td>\n",
       "      <td>0.013795</td>\n",
       "      <td>0.298083</td>\n",
       "      <td>38.143605</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>37</td>\n",
       "      <td>0.028217</td>\n",
       "      <td>0.013516</td>\n",
       "      <td>0.260757</td>\n",
       "      <td>43.394166</td>\n",
       "      <td>0.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>38</td>\n",
       "      <td>0.030372</td>\n",
       "      <td>0.013646</td>\n",
       "      <td>0.321502</td>\n",
       "      <td>33.745236</td>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>39</td>\n",
       "      <td>0.030347</td>\n",
       "      <td>0.013682</td>\n",
       "      <td>0.188581</td>\n",
       "      <td>29.724877</td>\n",
       "      <td>0.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>40</td>\n",
       "      <td>0.036984</td>\n",
       "      <td>0.016475</td>\n",
       "      <td>0.466823</td>\n",
       "      <td>27.449618</td>\n",
       "      <td>1.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>41</td>\n",
       "      <td>0.031638</td>\n",
       "      <td>0.014839</td>\n",
       "      <td>0.388590</td>\n",
       "      <td>23.450058</td>\n",
       "      <td>0.93</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    model       nll     brier       ece        mce  classification error\n",
       "0      17  0.032864  0.014360  0.407820  26.800570                  0.91\n",
       "1      18  0.033854  0.016187  0.383372  17.783421                  1.04\n",
       "2      19  0.026642  0.012424  0.364157  67.611680                  0.82\n",
       "3      20  0.038028  0.016371  0.484884  52.044736                  1.00\n",
       "4      21  0.031545  0.014283  0.395764  63.523687                  0.94\n",
       "5      22  0.029846  0.013624  0.256253  70.088703                  0.81\n",
       "6      23  0.040455  0.019717  0.303081  27.208157                  1.32\n",
       "7      24  0.030986  0.013966  0.319389  26.643641                  0.86\n",
       "8      25  0.039387  0.016895  0.399911  70.433485                  1.07\n",
       "9      26  0.030352  0.013360  0.304104  30.806845                  0.86\n",
       "10     27  0.042083  0.018238  0.521044  74.650011                  1.08\n",
       "11     28  0.030872  0.014010  0.471211  66.532917                  0.90\n",
       "12     29  0.035260  0.016887  0.330447  33.671738                  1.10\n",
       "13     30  0.031338  0.014635  0.435284  32.694436                  0.97\n",
       "14     31  0.034491  0.016913  0.279106  13.928951                  1.12\n",
       "15     32  0.031556  0.014473  0.356103  58.299924                  0.95\n",
       "16     33  0.041040  0.018445  0.358367  38.110917                  1.16\n",
       "17     34  0.037229  0.016927  0.352752  66.641052                  1.12\n",
       "18     35  0.036809  0.016937  0.512715  19.586023                  1.08\n",
       "19     36  0.029288  0.013795  0.298083  38.143605                  0.95\n",
       "20     37  0.028217  0.013516  0.260757  43.394166                  0.94\n",
       "21     38  0.030372  0.013646  0.321502  33.745236                  0.90\n",
       "22     39  0.030347  0.013682  0.188581  29.724877                  0.86\n",
       "23     40  0.036984  0.016475  0.466823  27.449618                  1.07\n",
       "24     41  0.031638  0.014839  0.388590  23.450058                  0.93"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ppe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PPE RESULTS (TEST SET)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "NLL\n",
      "0.034 ± 0.00\n",
      "--------------------\n",
      "BRIER\n",
      "0.015 ± 0.00\n",
      "--------------------\n",
      "ECE\n",
      "0.366 ± 0.08\n",
      "--------------------\n",
      "MCE\n",
      "42.119 ± 18.98\n",
      "--------------------\n",
      "CLASSIFICATION ERROR\n",
      "0.990 ± 0.12\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "print('PPE Results (test set)'.upper())\n",
    "print('-'*100)\n",
    "metrics = ['nll', 'brier', 'ece', 'mce', 'classification error']\n",
    "for metric in metrics:\n",
    "    print('{0}'.format(metric.upper()))\n",
    "    print('{0:.3f} \\u00B1 {1:.2f}'.format(np.mean(df_ppe[metric]), np.std(df_ppe[metric])))\n",
    "    print('-'*20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MC Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_mcdo(num_classes=10, dropout=True, level=0.5):\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "    model.add(BatchNormalization(momentum=.9))\n",
    "    \n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(BatchNormalization(momentum=.9))\n",
    "    if dropout:\n",
    "        model.add(Lambda(lambda x: K.dropout(x, level=level)))\n",
    "    \n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Flatten())\n",
    "    \n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(BatchNormalization(momentum=.9))\n",
    "    if dropout:\n",
    "        model.add(Lambda(lambda x: K.dropout(x, level=level)))\n",
    "    \n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(BatchNormalization(momentum=.9))\n",
    "    if dropout:\n",
    "        model.add(Lambda(lambda x: K.dropout(x, level=level)))\n",
    "    \n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 5e-4\n",
    "#\n",
    "output_baseline_dropout_folder = os.path.join(output_folder, 'baselines_dropout')\n",
    "if not os.path.isdir(output_baseline_dropout_folder):\n",
    "    os.makedirs(output_baseline_dropout_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(n_models):\n",
    "    seed = i+17\n",
    "    # change the random state\n",
    "    np.random.seed(seed)\n",
    "    # creating output folder for each of the baseline models\n",
    "    output_model_folder = os.path.join(output_baseline_dropout_folder, str(seed))\n",
    "    if not os.path.isdir(output_model_folder):\n",
    "        os.mkdir(output_model_folder)\n",
    "        # callbacks for training\n",
    "        callbacks = list()\n",
    "        log = CSVLogger(os.path.join(output_model_folder, 'log.csv'))\n",
    "        callbacks.append(log)\n",
    "        checkpoint_path = os.path.join(output_model_folder, 'weights.{epoch:02d}.hdf5')\n",
    "        checkpoint = ModelCheckpoint(checkpoint_path, period=1, save_best_only=False, verbose=True)\n",
    "        callbacks.append(checkpoint)\n",
    "        # initialize and compile the model\n",
    "        model = cnn_mcdo()\n",
    "        model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=learning_rate), metrics=['accuracy'])\n",
    "        # train\n",
    "        model.fit(x_train, y_train, batch_size=128, epochs=15, verbose=1, callbacks=callbacks, validation_data=(x_val, y_val), shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(17, 17+n_models):\n",
    "    log = pd.read_csv(os.path.join(output_baseline_dropout_folder, str(i), 'log.csv'))\n",
    "    plt.figure(figsize=(8,2),dpi=100)\n",
    "    plt.subplots_adjust(wspace=0.5)\n",
    "    ax1 = plt.subplot(121)\n",
    "    ax2 = plt.subplot(122)\n",
    "    for metric_type in ['', 'val_']:\n",
    "        for key in log.keys():\n",
    "            if 'loss' in key and 'val' not in key:\n",
    "                p = ax1.plot(log[metric_type+ key], label=metric_type + key+str(i), linewidth=1)\n",
    "                c = p[-1].get_color()\n",
    "                ax1.plot(np.argmin(log[metric_type+key]), np.amin(log[metric_type+key]), \n",
    "                         '*', markersize=10, alpha=0.5, color = c)\n",
    "                ax1.set_title('min val NLL: {0:.3f}'.format(np.amin(log['val_' + key])))\n",
    "                ax1.set_ylabel('NLL')\n",
    "                ax1.set_xlabel('epochs')\n",
    "            if 'acc' in key and 'val' not in key:\n",
    "                p = ax2.plot(log[metric_type + key], label=metric_type + key+str(i), linewidth=1)\n",
    "                c = p[-1].get_color()\n",
    "                ax2.plot(np.argmax(log[metric_type + key]), np.amax(log[metric_type + key]), \n",
    "                         '*', markersize=10, alpha=0.5, color=c)\n",
    "                ax2.set_title('max val acc: {0:.2f}'.format(np.amax(log['val_' + key]*100)))\n",
    "                ax2.set_ylabel('accuracy')\n",
    "                ax2.set_xlabel('epochs')\n",
    "    ax1.grid()\n",
    "    ax2.grid()\n",
    "    ax1.legend()\n",
    "    ax2.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, model_id in enumerate(range(17, 17+n_models)):\n",
    "    model_folder = os.path.join(output_baseline_dropout_folder, str(model_id))\n",
    "    test_pred_path = os.path.join(model_folder, 'test_pred.npy')\n",
    "    # if True:\n",
    "    if not os.path.isfile(test_pred_path):\n",
    "        checkpoint_path = glob.glob(model_folder + '/weights.' + str(epochs).zfill(2) + '*.hdf5')[0]\n",
    "        model = cnn_mcdo(dropout=False)\n",
    "        print('loading weights for model {}...'.format(model_id))\n",
    "        model.load_weights(checkpoint_path)\n",
    "        print('inference...')\n",
    "        test_pred = model.predict(x_test)\n",
    "        np.save(test_pred_path, test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_model_id = 17\n",
    "y_pred_sample = np.load(os.path.join(output_baseline_folder, str(sample_model_id), 'test_pred.npy'))\n",
    "shape = np.shape(y_pred_sample)\n",
    "all_test_preds = np.zeros((n_models, *shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = []\n",
    "for index, model_id in enumerate(range(17, 17 + n_models)):\n",
    "    y_pred = np.load(os.path.join(output_baseline_dropout_folder, str(model_id), 'test_pred.npy'))\n",
    "    all_test_preds[index] = y_pred\n",
    "    nll = log_loss(y_test, y_pred)\n",
    "    error = classification_error(y_test, y_pred)\n",
    "    br = brier_multi(y_test, y_pred)\n",
    "    calib_erros = CalibrationErrors(y_test, y_pred, bin_size=1 / 20., min_samples=0)\n",
    "    _, _, ece, mce, _ = calib_erros.calculate_calibration_errors()\n",
    "    d.append(OrderedDict({\"model\":model_id, \"nll\": nll, \"brier\": br, \"ece\": ece, \"mce\":mce, \"classification error\": error}))\n",
    "df_baselines_do = pd.DataFrame(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BASELINE DROPOUT RESULTS (TEST SET)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "NLL\n",
      "0.046 ± 0.03\n",
      "--------------------\n",
      "BRIER\n",
      "0.019 ± 0.01\n",
      "--------------------\n",
      "ECE\n",
      "0.589 ± 0.29\n",
      "--------------------\n",
      "MCE\n",
      "47.715 ± 13.74\n",
      "--------------------\n",
      "CLASSIFICATION ERROR\n",
      "1.179 ± 0.33\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "print('Baseline Dropout Results (test set)'.upper())\n",
    "print('-'*100)\n",
    "metrics = ['nll', 'brier', 'ece', 'mce', 'classification error']\n",
    "for metric in metrics:\n",
    "    print('{0}'.format(metric.upper()))\n",
    "    print('{0:.3f} \\u00B1 {1:.2f}'.format(np.mean(df_baselines_do[metric]), np.std(df_baselines_do[metric])))\n",
    "    print('-'*20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_mcdo_ensemble = 25\n",
    "for index, model_id in enumerate(range(17, 17+n_models)):\n",
    "    model_folder = os.path.join(output_baseline_dropout_folder, str(model_id))\n",
    "    output_mcdo_folder = os.path.join(model_folder, 'mcdo')\n",
    "    test_pred_path = os.path.join(output_mcdo_folder, 'test_pred_mcdo.npy')\n",
    "    # if True:\n",
    "    if not os.path.isfile(test_pred_path):\n",
    "        if not os.path.isdir(output_mcdo_folder):\n",
    "            os.mkdir(output_mcdo_folder)\n",
    "        checkpoint_path = glob.glob(model_folder + '/weights.' + str(epochs).zfill(2) + '*.hdf5')[0]\n",
    "        model = cnn_mcdo()\n",
    "        print('loading weights for model {}...'.format(model_id))\n",
    "        model.load_weights(checkpoint_path)\n",
    "        y_test_pred_ensemble = np.zeros((n_mcdo_ensemble, *y_test.shape))\n",
    "        for index2, seed in enumerate(range(17, 17 + n_mcdo_ensemble)):\n",
    "            np.random.seed(seed)\n",
    "            y_test_pred_dropout = model.predict(x_test, verbose=1)\n",
    "            y_test_pred_ensemble[index2] = y_test_pred_dropout\n",
    "        y_pred = np.mean(y_test_pred_ensemble, axis=0)\n",
    "        np.save(test_pred_path, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = list()\n",
    "for index, model_id in enumerate(range(17, 17 + n_models)):\n",
    "    model_mcdo_folder= os.path.join(output_baseline_dropout_folder, str(model_id),  'mcdo')\n",
    "    y_pred = np.load(os.path.join(model_mcdo_folder, 'test_pred_mcdo.npy'))\n",
    "    nll = log_loss(y_test, y_pred)\n",
    "    error = classification_error(y_test, y_pred)\n",
    "    br = brier_multi(y_test, y_pred)\n",
    "    calib_erros = CalibrationErrors(y_test, y_pred, bin_size=1 / 20., min_samples=0)\n",
    "    _, _, ece, mce, _ = calib_erros.calculate_calibration_errors()\n",
    "    d.append(OrderedDict({\"model\":model_id, \"nll\": nll, \"brier\": br, \"ece\": ece, \"mce\":mce, \"classification error\": error}))\n",
    "df_mcdo= pd.DataFrame(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>nll</th>\n",
       "      <th>brier</th>\n",
       "      <th>ece</th>\n",
       "      <th>mce</th>\n",
       "      <th>classification error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>0.030228</td>\n",
       "      <td>0.013708</td>\n",
       "      <td>0.786098</td>\n",
       "      <td>39.461466</td>\n",
       "      <td>0.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>0.031691</td>\n",
       "      <td>0.014284</td>\n",
       "      <td>0.817432</td>\n",
       "      <td>71.709560</td>\n",
       "      <td>0.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>0.031044</td>\n",
       "      <td>0.013723</td>\n",
       "      <td>0.728056</td>\n",
       "      <td>66.231902</td>\n",
       "      <td>0.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>0.032092</td>\n",
       "      <td>0.013702</td>\n",
       "      <td>0.866675</td>\n",
       "      <td>67.469836</td>\n",
       "      <td>0.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>21</td>\n",
       "      <td>0.033586</td>\n",
       "      <td>0.014869</td>\n",
       "      <td>0.785937</td>\n",
       "      <td>18.006981</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>22</td>\n",
       "      <td>0.031600</td>\n",
       "      <td>0.014381</td>\n",
       "      <td>0.819364</td>\n",
       "      <td>41.477634</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>23</td>\n",
       "      <td>0.028915</td>\n",
       "      <td>0.012811</td>\n",
       "      <td>0.788859</td>\n",
       "      <td>37.256537</td>\n",
       "      <td>0.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>24</td>\n",
       "      <td>0.030110</td>\n",
       "      <td>0.013116</td>\n",
       "      <td>0.930001</td>\n",
       "      <td>46.525903</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>25</td>\n",
       "      <td>0.032393</td>\n",
       "      <td>0.014452</td>\n",
       "      <td>0.760403</td>\n",
       "      <td>33.391998</td>\n",
       "      <td>0.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>26</td>\n",
       "      <td>0.032234</td>\n",
       "      <td>0.014276</td>\n",
       "      <td>0.880209</td>\n",
       "      <td>66.729956</td>\n",
       "      <td>0.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>27</td>\n",
       "      <td>0.031282</td>\n",
       "      <td>0.014083</td>\n",
       "      <td>0.868173</td>\n",
       "      <td>41.203472</td>\n",
       "      <td>0.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>28</td>\n",
       "      <td>0.029807</td>\n",
       "      <td>0.012954</td>\n",
       "      <td>0.794779</td>\n",
       "      <td>22.712928</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>29</td>\n",
       "      <td>0.031871</td>\n",
       "      <td>0.013694</td>\n",
       "      <td>0.909374</td>\n",
       "      <td>33.126876</td>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>30</td>\n",
       "      <td>0.028651</td>\n",
       "      <td>0.012271</td>\n",
       "      <td>0.913822</td>\n",
       "      <td>22.033246</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>31</td>\n",
       "      <td>0.030728</td>\n",
       "      <td>0.013714</td>\n",
       "      <td>0.850238</td>\n",
       "      <td>49.408659</td>\n",
       "      <td>0.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>32</td>\n",
       "      <td>0.031148</td>\n",
       "      <td>0.013214</td>\n",
       "      <td>0.954530</td>\n",
       "      <td>67.458083</td>\n",
       "      <td>0.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>33</td>\n",
       "      <td>0.029608</td>\n",
       "      <td>0.013337</td>\n",
       "      <td>0.823925</td>\n",
       "      <td>41.906745</td>\n",
       "      <td>0.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>34</td>\n",
       "      <td>0.028828</td>\n",
       "      <td>0.012634</td>\n",
       "      <td>0.809480</td>\n",
       "      <td>70.709301</td>\n",
       "      <td>0.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>35</td>\n",
       "      <td>0.031314</td>\n",
       "      <td>0.014051</td>\n",
       "      <td>0.743380</td>\n",
       "      <td>71.453943</td>\n",
       "      <td>0.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>36</td>\n",
       "      <td>0.032408</td>\n",
       "      <td>0.014367</td>\n",
       "      <td>0.804813</td>\n",
       "      <td>25.773757</td>\n",
       "      <td>0.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>37</td>\n",
       "      <td>0.032790</td>\n",
       "      <td>0.014364</td>\n",
       "      <td>0.858738</td>\n",
       "      <td>71.433140</td>\n",
       "      <td>0.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>38</td>\n",
       "      <td>0.031458</td>\n",
       "      <td>0.013893</td>\n",
       "      <td>0.823145</td>\n",
       "      <td>71.199735</td>\n",
       "      <td>0.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>39</td>\n",
       "      <td>0.032214</td>\n",
       "      <td>0.014134</td>\n",
       "      <td>0.741055</td>\n",
       "      <td>24.620846</td>\n",
       "      <td>0.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>40</td>\n",
       "      <td>0.033787</td>\n",
       "      <td>0.014785</td>\n",
       "      <td>0.903986</td>\n",
       "      <td>26.792200</td>\n",
       "      <td>0.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>41</td>\n",
       "      <td>0.032674</td>\n",
       "      <td>0.014056</td>\n",
       "      <td>0.848253</td>\n",
       "      <td>28.197583</td>\n",
       "      <td>0.88</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    model       nll     brier       ece        mce  classification error\n",
       "0      17  0.030228  0.013708  0.786098  39.461466                  0.82\n",
       "1      18  0.031691  0.014284  0.817432  71.709560                  0.89\n",
       "2      19  0.031044  0.013723  0.728056  66.231902                  0.82\n",
       "3      20  0.032092  0.013702  0.866675  67.469836                  0.82\n",
       "4      21  0.033586  0.014869  0.785937  18.006981                  0.92\n",
       "5      22  0.031600  0.014381  0.819364  41.477634                  0.92\n",
       "6      23  0.028915  0.012811  0.788859  37.256537                  0.83\n",
       "7      24  0.030110  0.013116  0.930001  46.525903                  0.76\n",
       "8      25  0.032393  0.014452  0.760403  33.391998                  0.85\n",
       "9      26  0.032234  0.014276  0.880209  66.729956                  0.82\n",
       "10     27  0.031282  0.014083  0.868173  41.203472                  0.79\n",
       "11     28  0.029807  0.012954  0.794779  22.712928                  0.80\n",
       "12     29  0.031871  0.013694  0.909374  33.126876                  0.84\n",
       "13     30  0.028651  0.012271  0.913822  22.033246                  0.72\n",
       "14     31  0.030728  0.013714  0.850238  49.408659                  0.82\n",
       "15     32  0.031148  0.013214  0.954530  67.458083                  0.77\n",
       "16     33  0.029608  0.013337  0.823925  41.906745                  0.78\n",
       "17     34  0.028828  0.012634  0.809480  70.709301                  0.78\n",
       "18     35  0.031314  0.014051  0.743380  71.453943                  0.86\n",
       "19     36  0.032408  0.014367  0.804813  25.773757                  0.87\n",
       "20     37  0.032790  0.014364  0.858738  71.433140                  0.97\n",
       "21     38  0.031458  0.013893  0.823145  71.199735                  0.86\n",
       "22     39  0.032214  0.014134  0.741055  24.620846                  0.89\n",
       "23     40  0.033787  0.014785  0.903986  26.792200                  0.96\n",
       "24     41  0.032674  0.014056  0.848253  28.197583                  0.88"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mcdo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MCDO RESULTS (TEST SET)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "NLL\n",
      "0.031 ± 0.00\n",
      "--------------------\n",
      "BRIER\n",
      "0.014 ± 0.00\n",
      "--------------------\n",
      "ECE\n",
      "0.832 ± 0.06\n",
      "--------------------\n",
      "MCE\n",
      "46.252 ± 18.90\n",
      "--------------------\n",
      "CLASSIFICATION ERROR\n",
      "0.842 ± 0.06\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "print('MCDO Results (test set)'.upper())\n",
    "print('-'*100)\n",
    "metrics = ['nll', 'brier', 'ece', 'mce', 'classification error']\n",
    "for metric in metrics:\n",
    "    print('{0}'.format(metric.upper()))\n",
    "    print('{0:.3f} \\u00B1 {1:.2f}'.format(np.mean(df_mcdo[metric]), np.std(df_mcdo[metric])))\n",
    "    print('-'*20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = [df_baselines,\n",
    "df_ppe,\n",
    "df_ts,\n",
    "df_mcdo,\n",
    "df_deep_ensembles\n",
    "      ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% nll\n",
      "0.036 $\\pm$ 0.00 &\n",
      "0.034 $\\pm$ 0.00 &\n",
      "0.032 $\\pm$ 0.00 &\n",
      "0.031 $\\pm$ 0.00 &\n",
      "0.021 $\\pm$ 0.00 \\\\\n",
      "----------------------------------------------------------------------------------------------------\n",
      "% brier\n",
      "0.016 $\\pm$ 0.00 &\n",
      "0.015 $\\pm$ 0.00 &\n",
      "0.015 $\\pm$ 0.00 &\n",
      "0.014 $\\pm$ 0.00 &\n",
      "0.010 $\\pm$ 0.00 \\\\\n",
      "----------------------------------------------------------------------------------------------------\n",
      "% ece\n",
      "0.517 $\\pm$ 0.07 &\n",
      "0.366 $\\pm$ 0.08 &\n",
      "0.259 $\\pm$ 0.06 &\n",
      "0.832 $\\pm$ 0.06 &\n",
      "0.288 $\\pm$ 0.05 \\\\\n",
      "----------------------------------------------------------------------------------------------------\n",
      "% mce\n",
      "48.253 $\\pm$ 13.45 &\n",
      "42.119 $\\pm$ 18.98 &\n",
      "45.456 $\\pm$ 15.53 &\n",
      "46.252 $\\pm$ 18.90 &\n",
      "44.856 $\\pm$ 17.03 \\\\\n",
      "----------------------------------------------------------------------------------------------------\n",
      "% classification error\n",
      "0.990 $\\pm$ 0.13 &\n",
      "0.990 $\\pm$ 0.12 &\n",
      "0.990 $\\pm$ 0.13 &\n",
      "0.842 $\\pm$ 0.06 &\n",
      "0.661 $\\pm$ 0.03 \\\\\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "metrics = ['nll', 'brier', 'ece', 'mce', 'classification error']\n",
    "for metric in metrics:\n",
    "    print('% {}'.format(metric))\n",
    "    for index, df in enumerate(dfs):\n",
    "        if index != len(dfs)-1:\n",
    "            print('{0:.3f} $\\pm$ {1:.2f} &'.format(np.mean(df[metric]), np.std(df[metric])))\n",
    "        else:\n",
    "            print('{0:.3f} $\\pm$ {1:.2f} \\\\\\\\'.format(np.mean(df[metric]), np.std(df[metric])))\n",
    "    print('-'*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
