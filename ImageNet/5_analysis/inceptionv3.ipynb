{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "version of: 2020/06/11 14:06\n",
      "==============================\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "now = datetime.datetime.now().strftime(\"%Y/%m/%d %H:%M\")\n",
    "print('=' * 30)\n",
    "print('version of: {0}'.format(now))\n",
    "print('=' * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "import sys\n",
    "\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import log_loss, brier_score_loss\n",
    "import seaborn as sns; sns.set(style=\"whitegrid\", color_codes=True)\n",
    "\n",
    "sys.path.append('../..')\n",
    "from helpers.settings import models_folder, arrays_folder, sheets_folder\n",
    "from helpers.utils import top_k_accuracy, calculate_confidence, plot_confidence, calculate_error, brier_multi, CalibrationErrors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_start_batch = 5\n",
    "n_selected = 45\n",
    "architecture = 'inceptionv3'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## reading arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    }
   ],
   "source": [
    "n_ensembles = 10\n",
    "n_samples = 50000\n",
    "n_batch = 50\n",
    "samples_per_batch = n_samples// n_batch\n",
    "print(samples_per_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = 1000\n",
    "y_pred_ensembles = dict()\n",
    "image_net_model_folder = os.path.join(models_folder, architecture)\n",
    "os.path.isdir(image_net_model_folder)\n",
    "y_pred_ensembles = np.zeros((n_ensembles, n_selected*samples_per_batch, n_classes))\n",
    "X = np.zeros((n_selected*samples_per_batch, 224,224,3), dtype=np.uint8)\n",
    "y_pred_base = np.zeros((n_selected*samples_per_batch, n_classes))\n",
    "y_true = np.zeros((n_selected*samples_per_batch, n_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 45/45 [00:50<00:00,  1.13s/it]\n"
     ]
    }
   ],
   "source": [
    "images_folder = os.path.join(arrays_folder, 'imagenet_224')\n",
    "image_net_model_folder = os.path.join(models_folder, architecture)\n",
    "for i in tqdm(range(n_selected)):\n",
    "    images_path = os.path.join(images_folder, 'x_val_' + str(i+n_start_batch).zfill(3) + '.npy')\n",
    "    base_path = os.path.join(image_net_model_folder, 'y_pred_base_' + str(i+n_start_batch) + '.npy')\n",
    "    true_path = os.path.join(image_net_model_folder, 'y_test_' + str(i+n_start_batch) + '.npy')\n",
    "    ensemble_path = os.path.join(image_net_model_folder, 'y_pred_ensemble_' + str(i+n_start_batch) + '.npy')\n",
    "    X[i*samples_per_batch: (i+1)*samples_per_batch] = np.load(images_path).astype(np.uint8)\n",
    "    y_pred_base[i*samples_per_batch: (i+1)*samples_per_batch] = np.load(base_path)\n",
    "    y_pred_ensembles[:, i*samples_per_batch: (i+1)*samples_per_batch] = np.load(ensemble_path)\n",
    "    y_true[i*samples_per_batch: (i+1)*samples_per_batch] = np.load(true_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_folder = os.path.join(image_net_model_folder, 'plots')\n",
    "if not os.path.isdir(output_folder):\n",
    "    os.mkdir(output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.rcParams['mathtext.fontset'] = 'stix'\n",
    "matplotlib.rcParams['mathtext.rm'] = 'stix'\n",
    "matplotlib.rcParams['mathtext.it'] = 'stix'\n",
    "matplotlib.rcParams['mathtext.fontset'] = 'stix'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sigma = 1.94\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(os.path.join(image_net_model_folder, 'golden_optimization_simgas.csv'))\n",
    "sigma_1 = df[df.iteration == 6].sigma_1.values[0]\n",
    "sigma_2 = df[df.iteration == 6].sigma_2.values[0]\n",
    "sigma_optimum = sigma_2 + (sigma_1 - sigma_2) / 2\n",
    "print('sigma = {0:.2f}'.format(sigma_optimum*1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_ensemble_mean = np.mean(y_pred_ensembles, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "nll_baseline = log_loss(y_true,y_pred_base)\n",
    "nll_perturbed = log_loss(y_true,y_pred_ensemble_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "k1_base = top_k_accuracy(y_true, y_pred_base)\n",
    "k5_base = top_k_accuracy(y_true, y_pred_base, 5)\n",
    "k1 = top_k_accuracy(y_true, y_pred_ensemble_mean)\n",
    "k5 = top_k_accuracy(y_true, y_pred_ensemble_mean, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_base_logit = np.log(y_pred_base)\n",
    "def softmax(y_logit):\n",
    "    return np.exp(y_logit)/np.sum(np.exp(y_logit), axis=-1)[:, np.newaxis]\n",
    "def softmax_t(y_logit, t):\n",
    "    return np.exp(y_logit/t)/np.sum(np.exp(y_logit/t), axis=-1)[:, np.newaxis]\n",
    "def ll_t(t):\n",
    "    y_pred_temp = softmax_t(y_pred_base_logit, t)\n",
    "    ll = log_loss(y_true, y_pred_temp)\n",
    "    return ll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimized temp: 0.91\n"
     ]
    }
   ],
   "source": [
    "temps = pd.read_csv(os.path.join(sheets_folder, 'imagenet_optimal_temps.csv'))\n",
    "min_t = temps[temps.model==architecture].temp.values[0]\n",
    "print('optimized temp: {0:.2f}'.format(min_t))\n",
    "y_pred_temp = softmax_t(y_pred_base_logit, t=min_t)\n",
    "nll_temp = log_loss(y_true, y_pred_temp)\n",
    "k1_temp = top_k_accuracy(y_true, y_pred_temp)\n",
    "k5_temp = top_k_accuracy(y_true, y_pred_temp, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "br_baseline = brier_multi(y_true,y_pred_base)\n",
    "br_temp = brier_multi(y_true,y_pred_temp)\n",
    "br_perturbed = brier_multi(y_true,y_pred_ensemble_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "NLL Baseline:0.994\n",
      "NLL Temp: 0.975\n",
      "NLL PPE: 0.950\n",
      "----------------------------------------------------------------------------------------------------\n",
      "BR Baseline:0.328\n",
      "BR Temp: 0.328\n",
      "BR PPE: 0.317\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Errors baseline: 22.96, 6.47\n",
      "Errors Temp: 22.96, 6.47\n",
      "Errors PPE 22.26: 6.05\n"
     ]
    }
   ],
   "source": [
    "print('-'*100)\n",
    "print('NLL Baseline:{0:.3f}'.format(nll_baseline))\n",
    "print('NLL Temp: {0:.3f}'.format(nll_temp))\n",
    "print('NLL PPE: {0:.3f}'.format(nll_perturbed))\n",
    "print('-'*100)\n",
    "print('BR Baseline:{0:.3f}'.format(br_baseline))\n",
    "print('BR Temp: {0:.3f}'.format(br_temp))\n",
    "print('BR PPE: {0:.3f}'.format(br_perturbed))\n",
    "print('-'*100)\n",
    "print('Errors baseline: {0:.2f}, {1:.2f}'.format(100-k1_base, 100-k5_base))\n",
    "print('Errors Temp: {0:.2f}, {1:.2f}'.format(100-k1_temp, 100-k5_temp))\n",
    "print('Errors PPE {0:.2f}: {1:.2f}'.format(100-k1, 100-k5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_mean_amax = np.amax(y_pred_ensemble_mean, axis=-1)\n",
    "y_pred_mean_argmax = np.argmax(y_pred_ensemble_mean, axis=-1)\n",
    "y_true_argmax = np.argmax(y_true, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "nll_ensemble_sep = -(np.sum(np.log(y_pred_ensemble_mean)*y_true, axis=1))\n",
    "nll_baseline_sep = -(np.sum(np.log(y_pred_base)*y_true, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "confidence_bl, acc_bl, ece_bl, mce_bl  = calculate_confidence(y_true, y_pred_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "confidence_temp, acc_temp, ece_temp, mce_temp  = calculate_confidence(y_true, y_pred_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "confidence_ppe, acc_ppe, ece_ppe, mce_ppe = calculate_confidence(y_true, y_pred_ensemble_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14,4), dpi=250)\n",
    "ax = plt.subplot(131)\n",
    "plot_confidence(confidence_bl, acc_bl, ax)\n",
    "ax.set_title('Baseline' )\n",
    "ax.text(0.64, 0.1, 'ECE: {0:0.2f}'.format(ece_bl), color='black',  bbox=dict(facecolor='white', edgecolor='black'))\n",
    "ax.set_xlabel('Confidence')\n",
    "ax.set_ylabel('Accuracy')\n",
    "ax = plt.subplot(132)\n",
    "plot_confidence(confidence_temp, acc_temp, ax)\n",
    "ax.set_title('Temp. Scaling (' + r'$T^*$' + ' = {0:.4f})'.format(min_t))\n",
    "ax.text(0.67, 0.1, 'ECE: {0:0.2f}'.format(ece_temp), color='black',  bbox=dict(facecolor='white', edgecolor='black'));\n",
    "ax.set_xlabel('Confidence')\n",
    "ax = plt.subplot(133)\n",
    "plot_confidence(confidence_ppe, acc_ppe, ax)\n",
    "ax.set_title('PPE (' + r'$\\rm{\\sigma*}$' + ' = {0:.4f})'.format(sigma_optimum))\n",
    "ax.text(0.69, 0.1, 'ECE: {0:0.2f}'.format(ece_ppe), color='black',  bbox=dict(facecolor='white', edgecolor='black'));\n",
    "ax.set_xlabel('Confidence')\n",
    "plt.savefig(os.path.join(output_folder, 'calibration_maps.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
